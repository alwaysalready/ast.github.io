<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Conferences Archives | Alex Taylor</title>
	<atom:link href="https://ast.io/archive/category/conferences/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>by Alex Taylor</description>
	<lastBuildDate>Fri, 17 Dec 2021 18:15:54 +0000</lastBuildDate>
	<language>en-GB</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.0</generator>
	<item>
		<title>Workshop CSCW 2021: Global Labours of AI and Data Intensive Systems</title>
		<link>/workshop-cscw-global-labours/</link>
					<comments>/workshop-cscw-global-labours/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Mon, 16 Aug 2021 12:57:27 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[cscw]]></category>
		<guid isPermaLink="false">/?p=5878</guid>

					<description><![CDATA[<p>Excited to announce #CSCW2021 workshop: “Global Labours of AI and Data Intensive Systems”.Will provide opportunities to discuss hidden labours behind AI + set the stage for critical modes of inquiry. Texts, pictorials, tik-tok vids, etc. due 15 Sep.See: https://t.co/EsVXAAGhPX pic.twitter.com/YJlrKHSF7A — Alex Taylor (@alxndrt) August 16, 2021 [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/workshop-cscw-global-labours/">Read More...<span class="screen-reader-text"> from Workshop CSCW 2021: Global Labours of AI and Data Intensive Systems</span></a></p>
<p>The post <a rel="nofollow" href="/workshop-cscw-global-labours/">Workshop CSCW 2021: Global Labours of AI and Data Intensive Systems</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<div class="row">
<div class="col-sm-1 col-md-3">
</div>
<div class="col-sm-9 mt-3">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Excited to announce <a href="https://twitter.com/hashtag/CSCW2021?src=hash&amp;ref_src=twsrc%5Etfw">#CSCW2021</a> workshop: “Global Labours of AI and Data Intensive Systems”.<br>Will provide opportunities to discuss hidden labours behind AI + set the stage for critical modes of inquiry.</p>
<p>Texts, pictorials, tik-tok vids, etc. due 15 Sep.<br>See: <a href="https://t.co/EsVXAAGhPX">https://t.co/EsVXAAGhPX</a> <a href="https://t.co/YJlrKHSF7A">pic.twitter.com/YJlrKHSF7A</a></p>
<p>— Alex Taylor (@alxndrt) <a href="https://twitter.com/alxndrt/status/1427253293143691269?ref_src=twsrc%5Etfw">August 16, 2021</a></p></blockquote>
<p> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</p></div>
</div>
<p>The post <a rel="nofollow" href="/workshop-cscw-global-labours/">Workshop CSCW 2021: Global Labours of AI and Data Intensive Systems</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/workshop-cscw-global-labours/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>CSCW 2021 conference paper</title>
		<link>/cscw-2021-conference-paper/</link>
					<comments>/cscw-2021-conference-paper/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Mon, 14 Jun 2021 09:31:44 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Publications]]></category>
		<category><![CDATA[conference]]></category>
		<category><![CDATA[cscw]]></category>
		<guid isPermaLink="false">/?p=5841</guid>

					<description><![CDATA[<p>A CSCW conference paper from this year. Abstract Prior work on AI-enabled assistive technology (AT) for people with visual impairments (VI) has treated navigation largely as an independent activity. Consequently, much effort has focused on providing individual users with wayfinding details about the environment, including information on distances, proximity, obstacles, and landmarks. However, independence is [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/cscw-2021-conference-paper/">Read More...<span class="screen-reader-text"> from CSCW 2021 conference paper</span></a></p>
<p>The post <a rel="nofollow" href="/cscw-2021-conference-paper/">CSCW 2021 conference paper</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<div class="row">
<div class="col-12 col-md-8 my-3">A CSCW conference paper from this year.</div>
<div class="col-12 col-md-7 my-4 offset-md-1">
<p class="wpmref"><span class="wpmauthors">Beatrice Vincenzi, Alex S Taylor, Simone Stumpf</span> <span class="wpmyear">(2021)</span> <span class="wpmtitle">Interdependence in Action: People with Visual Impairments and Their Guides Co-Constituting Common Spaces</span>, <span class="wpmoutlet">Proc. ACM Hum.-Comput. Interact.</span> <span class="wpmvolume">5</span><span class="wpmissue">(CSCW1)</span>, <span class="wpmpublisher">New York, NY, USA: Association for Computing Machinery</span>, <span class="wpmurl"><a target="_blank" href="https://ast.io/archive/download/5821/3449143.pdf"><span class="wpmurlpdf">pdf</span></a></span>, <span class="wpmurl"><a target="_blank" href="https://doi.org/10.1145/3449143"><span class="wpmurldoi:10.1145/3449143">doi:10.1145/3449143</span></a></span><br clear="all"></p>

<div class="small"><strong><em>Abstract</em></strong><br>
Prior work on AI-enabled assistive technology (AT) for people with visual impairments (VI) has treated navigation largely as an independent activity. Consequently, much effort has focused on providing individual users with wayfinding details about the environment, including information on distances, proximity, obstacles, and landmarks. However, independence is also achieved by people with VI through interacting with others, such as in collaboration with sighted guides. Drawing on the concept of interdependence, this research presents a systematic analysis of sighted guiding partnerships. Using interaction analysis as our primary mode of data analysis, we conducted an empirical, qualitative study with 4 couples, each made up of person with a vision impairment and their sighted guide. Our results show how pairs used interactional resources such as turn-taking and body movements to both co-constitute a common space for navigation, and repair moments of rupture to this space. This work is used to present an exemplary case of interdependence and draws out implications for designing AI-enabled AT that shifts the emphasis away from independent navigation, and towards the carefully coordinated actions between people navigating together.</div>
<div class="small"><strong><em><a class="download-link" title href="https://ast.io/archive/download/5821/" rel="nofollow">
	Interdependence in Action, CSCW 2021	(362 downloads)
</a></em></strong></div>
</div>
</div>
<p>The post <a rel="nofollow" href="/cscw-2021-conference-paper/">CSCW 2021 conference paper</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/cscw-2021-conference-paper/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>CHI 2021 conference papers</title>
		<link>/chi21-papers/</link>
					<comments>/chi21-papers/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Tue, 01 Jun 2021 08:58:56 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Publications]]></category>
		<category><![CDATA[CHI]]></category>
		<category><![CDATA[conference]]></category>
		<guid isPermaLink="false">/?p=5833</guid>

					<description><![CDATA[<p>Two papers at the CHI conference this year. Abstract The relationships that constitute the global industrial food system tend towards two dominant values that are creating unsustainable social and environmental inequalities. The first is a human-centered perspective on food that privileges humans over all other species. The second is a view of food as a [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/chi21-papers/">Read More...<span class="screen-reader-text"> from CHI 2021 conference papers</span></a></p>
<p>The post <a rel="nofollow" href="/chi21-papers/">CHI 2021 conference papers</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<div class="row">
<div class="col-12 col-md-8 my-3">Two papers at the CHI conference this year.</div>
<div class="col-12 col-md-7 my-4">
<p class="wpmref"><span class="wpmauthors">Sara Heitlinger, Lara Houston, Alex Taylor, Ruth Catlow</span> <span class="wpmyear">(2021)</span> <span class="wpmtitle">Algorithmic Food Justice: Co-Designing More-than-Human Blockchain Futures for the Food Commons</span>, <span class="wpmoutlet">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</span>, <span class="wpmpublisher">New York, NY, USA: Association for Computing Machinery</span>, <span class="wpmurl"><a target="_blank" href="https://ast.io/archive/download/5818/3411764.3445655.pdf"><span class="wpmurlpdf">pdf</span></a></span>, <span class="wpmurl"><a target="_blank" href="https://doi.org/10.1145/3411764.3445655"><span class="wpmurldoi:10.1145/3411764.3445655">doi:10.1145/3411764.3445655</span></a></span><br clear="all"></p>

<div class="small"><strong><em>Abstract</em></strong><br>
The relationships that constitute the global industrial food system tend towards two dominant values that are creating unsustainable social and environmental inequalities. The first is a human-centered perspective on food that privileges humans over all other species. The second is a view of food as a commodity to be traded for maximum economic value, rewarding a small number of shareholders. We present work that explores the unique algorithmic affordances of blockchain to create new types of value exchange and governance in the food system. We describe a project that used roleplay with urban agricultural communities to co-design blockchain-based food futures and explore the conditions for creating a thriving multispecies food commons. We discuss how the project helped rethink algorithmic food justice by reconfiguring more-than-human values and reconfiguring food as more-than-human commons. We also discuss some of the challenges and tensions arising from these explorations.
</div>
<div class="small"><strong><em><a class="download-link" title href="https://ast.io/archive/download/5818/" rel="nofollow">
	Algorithmic Food Justice, CHI 2021	(286 downloads)
</a></em></strong></div>
</div>
<div class="col-12 col-md-7 my-4 offset-md-2">
<p class="wpmref"><span class="wpmauthors">Cecily Morrison, Edward Cutrell, Martin Grayson, Anja Thieme, Alex Taylor, Geert Roumen, Camilla Longden, Sebastian Tschiatschek, Rita Faia Marques, Abigail Sellen</span> <span class="wpmyear">(2021)</span> <span class="wpmtitle">Social Sensemaking with AI: Designing an Open-Ended AI Experience with a Blind Child</span>, <span class="wpmoutlet">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</span>, <span class="wpmpublisher">New York, NY, USA: Association for Computing Machinery</span>, <span class="wpmurl"><a target="_blank" href="https://ast.io/archive/download/5824/3411764.3445290.pdf"><span class="wpmurlpdf">pdf</span></a></span>, <span class="wpmurl"><a target="_blank" href="https://doi.org/10.1145/3411764.3445290"><span class="wpmurldoi:10.1145/3411764.3445290">doi:10.1145/3411764.3445290</span></a></span><br clear="all"></p>

<div class="small"><strong>Abstract</strong><br>
AI technologies are often used to aid people in performing discrete tasks with well-defined goals (e.g., recognising faces in images). Emerging technologies that provide continuous, real-time information enable more open-ended AI experiences. In partnership with a blind child, we explore the challenges and opportunities of designing human-AI interaction for a system intended to support social sensemaking. Adopting a research-through-design perspective, we reflect upon working with the uncertain capabilities of AI systems in the design of this experience. We contribute: (i) a concrete example of an open-ended AI system that enabled a blind child to extend his own capabilities; (ii) an illustration of the delta between imagined and actual use, highlighting how capabilities derive from the human-AI interaction and not the AI system alone; and (iii) a discussion of design choices to craft an ongoing human-AI interaction that addresses the challenge of uncertain outputs of AI systems.
</div>
<div class="small"><strong><em><a class="download-link" title href="https://ast.io/archive/download/5824/" rel="nofollow">
	Social Sensemaking with AI, CHI 2021	(198 downloads)
</a></em></strong></div>
</div>
</div>
<p>The post <a rel="nofollow" href="/chi21-papers/">CHI 2021 conference papers</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/chi21-papers/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Conference papers</title>
		<link>/conference-papers-2020/</link>
					<comments>/conference-papers-2020/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Thu, 18 Jun 2020 08:48:54 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Publications]]></category>
		<category><![CDATA[CHI]]></category>
		<category><![CDATA[conference]]></category>
		<category><![CDATA[cscw]]></category>
		<guid isPermaLink="false">/?p=5761</guid>

					<description><![CDATA[<p>I’ve been slow to share papers here, so posting about two recently published papers. With both publications it was a absolute joy and privilege to work with my co-authors. Abstract Current approaches to AI and Assistive Technology (AT) often foreground task completion over other encounters such as expressions of care. Our paper challenges and complements [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/conference-papers-2020/">Read More...<span class="screen-reader-text"> from Conference papers</span></a></p>
<p>The post <a rel="nofollow" href="/conference-papers-2020/">Conference papers</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<div class="row">
<div class="col-12 col-md-8 my-3">I’ve been slow to share papers here, so posting about two recently published papers. With both publications it was a absolute joy and privilege to work with my co-authors.</div>
<div class="col-12 col-md-7 my-4">
<p class="wpmref"><span class="wpmauthors">Cynthia L Bennett, Daniela K Rosner, Alex S Taylor</span> <span class="wpmyear">(2020)</span> <span class="wpmtitle">The Care Work of Access</span>, <span class="wpmoutlet">CHI ’20</span>, <span class="wpmpages">p. 1–15</span>, <span class="wpmpublisher">New York, NY: ACM Press</span>, <span class="wpmurl"><a target="_blank" href="https://ast.io/archive/download/5689/care_work_access_2020.pdf"><span class="wpmurlpdf">pdf</span></a></span>, <span class="wpmurl"><a target="_blank" href="https://doi.org/10.1145/3313831.3376568"><span class="wpmurldoi:10.1145/3313831.3376568">doi:10.1145/3313831.3376568</span></a></span><br clear="all"></p>

<div class="small"><strong><em>Abstract</em></strong><br>
Current approaches to AI and Assistive Technology (AT) often foreground task completion over other encounters such as expressions of care. Our paper challenges and complements such task-completion approaches by attending to the care work of access-the continual affective and emotional adjustments that people make by noticing and attending to one another. We explore how this work impacts encounters among people with and without vision impairments who complete tasks together. We find that bound up in attempts to get things done are concerns for one another and how well people are doing together. Reading this work through emerging disability studies and feminist STS scholarship, we account for two important forms of work that give rise to access: (1) mundane attunements and (2) non-innocent authorizations. Together these processes work as sensitizing concepts to help HCI scholars account for the ways that intelligent ATs both produce access while sometimes subverting people with disabilities.</div>
<div class="small"><strong><em><a class="download-link" title="Version published" href="https://ast.io/archive/download/5689/" rel="nofollow">
	The care work of access, CHI 2020	(571 downloads)
</a></em></strong></div>
</div>
<div class="col-12 col-md-7 my-4 offset-md-2">
<p class="wpmref"><span class="wpmauthors">Jessica L Feuston, Alex S Taylor, Anne Marie Piper</span> <span class="wpmyear">(2020)</span> <span class="wpmtitle">Conformity of Eating Disorders through Content Moderation</span>, <span class="wpmoutlet">Proc. ACM Hum.-Comput. Interact.</span> <span class="wpmvolume">4</span><span class="wpmissue">(CSCW1)</span>, <span class="wpmpublisher">New York, NY, USA: Association for Computing Machinery</span>, <span class="wpmurl"><a target="_blank" href="https://ast.io/archive/download/5716/feuston-taylor-piper-2020.pdf"><span class="wpmurlpdf">pdf</span></a></span>, <span class="wpmurl"><a target="_blank" href="https://doi.org/10.1145/3392845"><span class="wpmurldoi:10.1145/3392845">doi:10.1145/3392845</span></a></span><br clear="all"></p>

<div class="small"><strong>Abstract</strong><br>
For individuals with mental illness, social media platforms are considered spaces for sharing and connection. However, not all expressions of mental illness are treated equally on these platforms. Different aggregates of human and technical control are used to report and ban content, accounts, and communities. Through two years of digital ethnography, including online observation and interviews, with people with eating disorders, we examine the experience of content moderation. We use a constructivist grounded theory approach to analysis that shows how practices of moderation across different platforms have particular consequences for members of marginalized groups, who are pressured to conform and compelled to resist. Above all, we argue that platform moderation is enmeshed with wider processes of conformity to specific versions of mental illness. Practices of moderation reassert certain bodies and experiences as ‘normal’ and valued, while rejecting others. At the same time, navigating and resisting these normative pressures further inscribes the marginal status of certain individuals. We discuss changes to the ways that platforms handle content related to eating disorders by drawing on the concept of multiplicity to inform design.</div>
<div class="small"><strong><em><a class="download-link" title="Version published" href="https://ast.io/archive/download/5716/" rel="nofollow">
	Conformity of eating disorders, CSCW 2020	(535 downloads)
</a></em></strong></div>
</div>
</div>
<p>The post <a rel="nofollow" href="/conference-papers-2020/">Conference papers</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/conference-papers-2020/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>CHI Workshop</title>
		<link>/chi19-workshop-paper/</link>
					<comments>/chi19-workshop-paper/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Sun, 05 May 2019 10:21:50 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Writing]]></category>
		<guid isPermaLink="false">/?p=4804</guid>

					<description><![CDATA[<p> [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/chi19-workshop-paper/">Read More...<span class="screen-reader-text"> from CHI Workshop</span></a></p>
<p>The post <a rel="nofollow" href="/chi19-workshop-paper/">CHI Workshop</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<div class="row">
<div class="col-sm-9">
<div>
<p>Very happy to have participated in the <a href="https://chi2019.acm.org/" rel="noopener noreferrer" target="_blank">CHI ’19</a> conference workshop:<br>
<a href="https://authentic.sice.indiana.edu/philosophy-hci-workshop/" rel="noopener noreferrer" target="_blank"><em>Exploring the Intersection of Philosophy and HCI</em></a>
</p>
</div>
<div>
<p>
<a href="https://twitter.com/strangertohabit?lang=en" rel="noopener noreferrer" target="_blank">Ann Light</a> and I wrote a short piece for the workshop:
</p>
</div>
<div class="highlight">
<p>
<a href="http://bit.ly/is-hope" rel="noopener noreferrer" target="_blank">The Name of the Title is Hope</a>
</p>
</div>
</div>
<div class="col-sm-12">
<img src="/archive/wp-content/uploads/2019/05/Multispecies-multiscalar-relations.png" alt="Figure from paper: Figure 1: Multispecies, multiscalar relations.">
</div>
<div class="col-sm-8 col-lg-6 mt-3">
<div class="small">
<p><strong>ABSTRACT</strong>: This short piece, far too short for the space it demands, spins together a lively and unwieldy story about methods—the practices we in design and design research follow to both know about the world and to have an affect on it. We speculate on a mode of doing design inflected with questions about what we are doing when we study and intervene in the world. This is a project full with the hope of renewed designerly methods that make more of/in the world; that promote a flourishing of difference; and that might just lead to modest but better ways of living and dying together. Our philosophy (if that is not too grand a word for it) comes less from a ”standing on the shoulders” of any one person, and more a thinking through and with feminist ways of knowing, doing, and being. Weaving into a mesh of ideas from the likes of Barad, Derrida, Dewey, Durkheim, Hacking, Haraway, Law, Stengers, and so on, we find there to be troubles between the ways we come to know the world (doings, methods or practices), and what we know (knowings or theories). The problematic distinction between such doings and knowings, and the murky worlds between them, open up a space for thinking-doing a world otherwise. When we come to accept that what we do and what we know are always already together, and that this ’togetherness’ is all the world can be, then we, in design, are left with a beginning: “<em>What worlds do we want to do-know?</em>”</p>
<div>
<div class="mt-sm-1">
<p>Download <a href="http://bit.ly/is-hope">PDF</a></p>
</div>
</div>
</div>

</div></div><p>The post <a rel="nofollow" href="/chi19-workshop-paper/">CHI Workshop</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/chi19-workshop-paper/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>EASST 2018 Presentation</title>
		<link>/easst-2018-presentation/</link>
					<comments>/easst-2018-presentation/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Wed, 01 Aug 2018 08:53:07 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Talks]]></category>
		<category><![CDATA[Biology]]></category>
		<category><![CDATA[design]]></category>
		<category><![CDATA[STS]]></category>
		<guid isPermaLink="false">/?p=4291</guid>

					<description><![CDATA[<p>Abigail Durrant and I gave our paper “Modelling Cells in/with risky comakings and devious worlds” at EASST last week, in the fabulous Feminist Figures panel. Very excited to see @alxndrt and @abigail_durrant present today in #feministfigures you both rocked! Not my best pic of the day but I really wanted to show this slide with [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/easst-2018-presentation/">Read More...<span class="screen-reader-text"> from EASST 2018 Presentation</span></a></p>
<p>The post <a rel="nofollow" href="/easst-2018-presentation/">EASST 2018 Presentation</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<div class="row" style="margin-bottom: 1rem;">
<div class="col-9 col-sm-9 col-md-5"><a href="https://twitter.com/abigail_durrant?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed&amp;ref_url=https%3A%2F%2Ftwitter.com%2Fanotherwindle" rel="noopener noreferrer" target="_blank">Abigail Durrant</a> and I gave our paper “Modelling Cells in/with risky comakings and devious worlds” at <a href="https://easst.net/conferences/" rel="noopener noreferrer" target="_blank">EASST</a> last week, in the fabulous <a href="https://twitter.com/search?l=&amp;q=%23feministfigures%20since%3A2018-05-27%20until%3A2018-08-03&amp;src=typd&amp;lang=en-gb" rel="noopener noreferrer" target="_blank">Feminist Figures</a> panel.</div>
<div class="small col-9 col-sm-9 col-md-7">
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">Very excited to see <a href="https://twitter.com/alxndrt?ref_src=twsrc%5Etfw">@alxndrt</a> and <a href="https://twitter.com/abigail_durrant?ref_src=twsrc%5Etfw">@abigail_durrant</a> present today in <a href="https://twitter.com/hashtag/feministfigures?src=hash&amp;ref_src=twsrc%5Etfw">#feministfigures</a> you both rocked! Not my best pic of the day but I really wanted to show this slide with <a href="https://twitter.com/hashtag/Haraway?src=hash&amp;ref_src=twsrc%5Etfw">#Haraway</a>’s game of cats cradle in the background <a href="https://twitter.com/hashtag/EASST2018?src=hash&amp;ref_src=twsrc%5Etfw">#EASST2018</a> <a href="https://t.co/JWRqn34k0F">pic.twitter.com/JWRqn34k0F</a></p>
<p>— Dr Amanda Windle (@anotherwindle) <a href="https://twitter.com/anotherwindle/status/1022212792013742082?ref_src=twsrc%5Etfw">July 25, 2018</a></p></blockquote>
<p> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</p></div>
</div>
<div class="row" style="margin-bottom: 1rem;">
<div class="col-9 col-sm-9 col-md-5">
<p class="highlight">Modelling cells in/with risky comakings and devious worlds</p>
</div>
<div class="small col-9 col-sm-9 col-md-7">
<strong>ABSTRACT</strong><br>
We use String Figures and Involutionary Momentum to “read against the grain” of a contemporaneous biology characterised by reduction. Working through the design of a tool that models cellular stability, we spin a yarn of “affectively charged” relations between researchers, cells and technologies.<br>
Drawing from her foundational studies of biology, Evelyn Fox Keller (2009:301) writes of a complexity and connectedness that might just characterise our “devious” world(s). She has traced threads through biology for over 40 years, drawing attention to—amongst other things—how it has often resisted the explanatory powers conferred upon its counterparts in other natural sciences. A pragmatic approach has dominated, she extols, in which unknowns have been a part of biology’s messy reality.<br>
Looking ahead, to the deepening entanglements between biology and computation, we find contemporaneous imaginaries surrounding cellular life to be testing this lineage. Certainly—as Keller herself has reflected—computation makes possible very particular modes of understanding, ones conforming to the “reductive, mechanistic, and adaptationist logics” that characterise a prevailing neo-Darwinism (Hustak &amp; Myers 2013:77).<br>
In this paper, we wish to cut across what on the face it appears to be biology’s narrowing move. By ‘looking askew’, we hope to ask more about biology and whether or not it is being rendered computational. Examining a project invested in the computational challenges of modelling cellular stability, and relying on the “risky comakings” (Haraway 2016:14) between actors, algorithms and computational tools, we stay committed to the troubles enlivened by knotted relations. We use two feminist figures, Haraway’s String Figure, and Hustak and Myer’s Involutionary Momentum, to (re-)tell a story of unfolding relationships between researchers, cells and technologies, spinning a yarn of “affectively charged” (Hustak &amp; Myers 2013) relays and knottings that resist singular figurings.<br>
<strong>References</strong><br>
Haraway, D.J., 2016. Staying with the trouble: Making kin in the Chthulucene. Duke University Press.<br>
Hustak, C. and Myers, N., 2012. Involutionary momentum: Affective ecologies and the sciences of plant/insect encounters. differences, 23(3), pp.74–118.<br>
Keller, E.F., 2009. Making sense of life: Explaining biological development with models, metaphors, and machines. Harvard University Press.
</div>
</div>
<p>The post <a rel="nofollow" href="/easst-2018-presentation/">EASST 2018 Presentation</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/easst-2018-presentation/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Papers presented at CHI ’18</title>
		<link>/papers-chi-2018/</link>
					<comments>/papers-chi-2018/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Thu, 03 May 2018 10:41:31 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Publications]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[CHI]]></category>
		<category><![CDATA[HCI]]></category>
		<guid isPermaLink="false">/?p=4104</guid>

					<description><![CDATA[<p>Delighted to see the two great papers I contributed to being presented at CHI 2018 in Montreal. Award winning paper talk about chatbots and race. — RW pic.twitter.com/C4rClKRzf1 — ACM CHI Conference (@sig_chi) April 24, 2018 Ari Schlesinger, Kenton O’Hara and Alex Taylor (2018) Lets Talk about Race: Identity, Chatbots, and AI. In Proceedings CHI [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/papers-chi-2018/">Read More...<span class="screen-reader-text"> from Papers presented at CHI ’18</span></a></p>
<p>The post <a rel="nofollow" href="/papers-chi-2018/">Papers presented at CHI ’18</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>Delighted to see the two great papers I contributed to being presented at CHI 2018 in Montreal.</p>
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">Award winning paper talk about chatbots and race. — RW <a href="https://t.co/C4rClKRzf1">pic.twitter.com/C4rClKRzf1</a></p>
<p>— ACM CHI Conference (@sig_chi) <a href="https://twitter.com/sig_chi/status/988875868914290688?ref_src=twsrc%5Etfw">April 24, 2018</a></p></blockquote>
<p> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p style="margin:1rem 30% 0 0">Ari Schlesinger, Kenton O’Hara and Alex Taylor (2018) <strong>Lets Talk about Race: Identity, Chatbots, and AI.</strong> <em>In Proceedings CHI ’18</em>. ACM Press. <a id="tippy_tip0_9032_anchor"></a></p>
<p><span class="entry-meta"><a href="https://ast.io/archive/download/3850/" rel="noopener noreferrer" target="_blank">pdf</a> (1282 downloads)</span>
</p><blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">Anja <a href="https://twitter.com/anja_thieme?ref_src=twsrc%5Etfw">@anja_thieme</a> doing a fab job presenting all the months of time and thought we’ve put into an expansive idea of capability <a href="https://twitter.com/hashtag/chi2018?src=hash&amp;ref_src=twsrc%5Etfw">#chi2018</a> <a href="https://twitter.com/MSFTResearch?ref_src=twsrc%5Etfw">@MSFTResearch</a> <a href="https://twitter.com/MSFTResearchCam?ref_src=twsrc%5Etfw">@MSFTResearchCam</a> <a href="https://t.co/fZ5SdpGFh5">pic.twitter.com/fZ5SdpGFh5</a></p>
<p>— Alex Taylor (@alxndrt) <a href="https://twitter.com/alxndrt/status/988857696085528576?ref_src=twsrc%5Etfw">April 24, 2018</a></p></blockquote>
<p style="margin:1rem 30% 0 0">Anja Thieme, Cynthia L. Bennett, Cecily Morrison, Edward Cutrell and Alex Taylor (2018) <strong>“I can do everything but see!” – How People with Vision Impairments Negotiate their Abilities in Social Contexts.</strong> <em>In Proceedings CHI ’18</em>. ACM Press. <a id="tippy_tip1_3042_anchor"></a></p>
<p><span class="entry-meta"><a href="https://ast.io/archive/download/3859/" rel="noopener noreferrer" target="_blank">pdf</a> (879 downloads)</span></p>
<div class="tippy" data-title="Abstract" data-showtitle="false" data-anchor="#tippy_tip0_9032_anchor"><strong>Abstract</strong> — Why is it so hard for chatbots to talk about race? This work explores how the biased contents of databases, the syntactic focus of natural language processing, and the opaque nature of deep learning algorithms cause chatbots difficulty in handling race-talk. In each of these areas, the tensions between race and chatbots create new opportunities for people and machines. By making the abstract and disparate qualities of this problem space tangible, we can develop chatbots that are more capable of handling race-talk in its many forms. Our goal is to provide the HCI community with ways to begin addressing the question, how can chatbots handle race-talk in new and improved ways?</div>
<div class="tippy" data-title="Abstract" data-showtitle="false" data-anchor="#tippy_tip1_3042_anchor"><strong>Abstract</strong> — This research takes an orientation to visual impairment (VI) that does not regard it as fixed or determined alone in or through the body. Instead, we consider (dis)ability as produced through interactions with the environment and configured by the people and technology within it. Specifically, we explore how abilities become negotiated through video ethnography with six VI athletes and spectators during the Rio 2016 Paralympics. We use generated in-depth examples to identify how technology can be a meaningful part of ability negotiations, emphasizing how these embed into the social interactions and lives of people with VI. In contrast to treating technology as a solution to a ‘sensory deficit’, we understand it to support the triangulation process of sense-making through provision of appropriate additional information. Further, we suggest that technology should not try and replace human assistance, but instead enable people with VI to better identify and interact with other people in-situ.</div>
<p>The post <a rel="nofollow" href="/papers-chi-2018/">Papers presented at CHI ’18</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/papers-chi-2018/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>CHI 2018 papers.</title>
		<link>/chi-2018-papers/</link>
					<comments>/chi-2018-papers/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Mon, 05 Feb 2018 21:56:52 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Writing]]></category>
		<category><![CDATA[blind and vision impaired]]></category>
		<category><![CDATA[CHI]]></category>
		<category><![CDATA[HCI]]></category>
		<category><![CDATA[intelligence]]></category>
		<guid isPermaLink="false">/?p=3871</guid>

					<description><![CDATA[<p>Anja Thieme, Cynthia L. Bennett, Cecily Morrison, Edward Cutrell and Alex Taylor (2018) “I can do everything but see!” – How People with Vision Impairments Negotiate their Abilities in Social Contexts. In Proceedings CHI ’18. ACM Press. ( downloads) Ari Schlesinger, Kenton O’Hara and Alex Taylor (2018) Lets Talk about Race: Identity, Chatbots, and AI. [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/chi-2018-papers/">Read More...<span class="screen-reader-text"> from CHI 2018 papers.</span></a></p>
<p>The post <a rel="nofollow" href="/chi-2018-papers/">CHI 2018 papers.</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<div class="call-out">
<p>Anja Thieme, Cynthia L. Bennett, Cecily Morrison, Edward Cutrell and Alex Taylor (2018) <strong>“I can do everything but see!” – How People with Vision Impairments Negotiate their Abilities in Social Contexts.</strong> <em>In Proceedings CHI ’18</em>. ACM Press. <a id="tippy_tip2_4205_anchor"></a></p>
<p><span class="entry-meta"><a href="https://ast.io/archive/download/3859/" rel="noopener noreferrer" target="_blank">pdf</a> (879 downloads)</span></p>
<p style="margin-top:6rem">Ari Schlesinger, Kenton O’Hara and Alex Taylor (2018) <strong>Lets Talk about Race: Identity, Chatbots, and AI.</strong> <em>In Proceedings CHI ’18</em>. ACM Press. <a id="tippy_tip3_2370_anchor"></a></p>
<p><span class="entry-meta"><a href="https://ast.io/archive/download/3850/" rel="noopener noreferrer" target="_blank">pdf</a> (1282 downloads)</span></p></div>
<div class="left-of-call-out">
<p>Very happy to have contributed to two papers being presented at the upcoming <a href="https://chi2018.acm.org/" rel="noopener noreferrer" target="_blank">CHI conference</a> this year. One reports on work with the blind and vision impaired a few of us have been involved in different ways (see <a href="https://ast.io/archive/research/#capability" rel="noopener">here</a>). Broadly, we’ve used the piece to reflect on the relations between vision impairment and artificial intelligence, and set out directions for a possible design space.</p>
<p style="margin:3rem 0 2rem 0;">The second paper picks up on a new theme for me, but one closely related to past reflections and design work around <a href="https://ast.io/archive/research/#intelauto">machine intelligence</a>. With the fantastic <a href="http://arischlesinger.com/" rel="noopener noreferrer" target="_blank">Ari Schlesinger</a> (GA Tech) leading the research, we examine the challenges faced in handling race talk (and racism) in human-bot interactions. Taking both Tai AI and the blacklist as starting points, we take seriously the computational underpinnings of chat bots and conversational agents, to underscore the role they have in sustaining troubling racial categories and the conditions they make possible for more just and equitable ways forward.</p>
</div>
<div class="tippy" data-title="Abstract" data-showtitle="false" data-anchor="#tippy_tip2_4205_anchor"><strong>Abstract</strong> — This research takes an orientation to visual impairment (VI) that does not regard it as fixed or determined alone in or through the body. Instead, we consider (dis)ability as produced through interactions with the environment and configured by the people and technology within it. Specifically, we explore how abilities become negotiated through video ethnography with six VI athletes and spectators during the Rio 2016 Paralympics. We use generated in-depth examples to identify how technology can be a meaningful part of ability negotiations, emphasizing how these embed into the social interactions and lives of people with VI. In contrast to treating technology as a solution to a ‘sensory deficit’, we understand it to support the triangulation process of sense-making through provision of appropriate additional information. Further, we suggest that technology should not try and replace human assistance, but instead enable people with VI to better identify and interact with other people in-situ.</div>
<div class="tippy" data-title="Abstract" data-showtitle="false" data-anchor="#tippy_tip3_2370_anchor"><strong>Abstract</strong> — Why is it so hard for chatbots to talk about race? This work explores how the biased contents of databases, the syntactic focus of natural language processing, and the opaque nature of deep learning algorithms cause chatbots difficulty in handling race-talk. In each of these areas, the tensions between race and chatbots create new opportunities for people and machines. By making the abstract and disparate qualities of this problem space tangible, we can develop chatbots that are more capable of handling race-talk in its many forms. Our goal is to provide the HCI community with ways to begin addressing the question, how can chatbots handle race-talk in new and improved ways?</div>
<p>The post <a rel="nofollow" href="/chi-2018-papers/">CHI 2018 papers.</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/chi-2018-papers/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Paper presented at Assets</title>
		<link>/assets-2017/</link>
					<comments>/assets-2017/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Sat, 02 Dec 2017 10:05:05 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Presenting]]></category>
		<category><![CDATA[Publications]]></category>
		<category><![CDATA[accessible computing]]></category>
		<category><![CDATA[blind and vision impaired]]></category>
		<guid isPermaLink="false">/?p=3805</guid>

					<description><![CDATA[<p>I’m very happy to have been a part of the work leading up to a paper presented at Assets 2017, the ACM conference on Accessible Computing. Reporting on work from a group of us at Microsoft Research, the paper describes an orientation to our studies with the blind and vision impaired. Cecily Morrison, Edward Cutrell, [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/assets-2017/">Read More...<span class="screen-reader-text"> from Paper presented at Assets</span></a></p>
<p>The post <a rel="nofollow" href="/assets-2017/">Paper presented at Assets</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>I’m very happy to have been a part of the work leading up to a paper presented at <a href="https://assets17.sigaccess.org/" rel="noopener noreferrer" target="_blank">Assets 2017</a>, the ACM conference on Accessible Computing. Reporting on work from a group of us at Microsoft Research, the paper describes an orientation to our studies with the blind and vision impaired.</p>
<blockquote class="small"><p>Cecily Morrison, Edward Cutrell, Anupama Dhareshwar, Kevin Doherty, Anja Thieme, and Alex Taylor. 2017. <strong>Imagining Artificial Intelligence Applications with People with Visual Disabilities using Tactile Ideation</strong>. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility (<em>ASSETS ’17</em>). ACM, New York, NY, USA, 81–90. <a href="https://doi.org/10.1145/3132525.3132530" rel="noopener noreferrer" target="_blank">DOI</a>.</p></blockquote>
<p><span id="more-3805"></span></p>
<blockquote><p><strong>ABSTRACT</strong><br>
There has been a surge in artificial intelligence (AI) technologies co-opted by or designed for people with visual disabilities. Researchers and engineers have pushed technical boundaries in areas such as computer vision, natural language processing, location inference, and wearable computing. But what do people with visual disabilities imagine as their own technological future? To explore this question, we developed and carried out tactile ideation workshops with participants in the UK and India. Our participants generated a large and diverse set of ideas, most focusing on ways to meet needs related to social interaction. In some cases, this was a matter of recognizing people. In other cases, they wanted to be able to participate in social situations without foregrounding their disability. It was striking that this finding was consistent across UK and India despite substantial cultural and infrastructural differences. In this paper, we describe a new technique for working with people with visual disabilities to imagine new technologies that are tuned to their needs and aspirations. Based on our experience with these workshops, we provide a set of social dimensions to consider in the design of new AI technologies: social participation, social navigation, social maintenance, and social independence. We offer these social dimensions as a starting point to forefront users’ social needs and desires as a more deliberate consideration for assistive technology design.</p></blockquote>
<p>Download a copy of the paper <a href="https://ast.io/archive/download/3684/" rel="noopener noreferrer" target="_blank">here</a>.</p>
<p>The post <a rel="nofollow" href="/assets-2017/">Paper presented at Assets</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/assets-2017/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Paper at 4S 2017</title>
		<link>/4s-acceptance-2017/</link>
					<comments>/4s-acceptance-2017/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Mon, 24 Apr 2017 08:45:29 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Presenting]]></category>
		<category><![CDATA[Writing]]></category>
		<category><![CDATA[4S]]></category>
		<category><![CDATA[STS]]></category>
		<guid isPermaLink="false">/?p=3288</guid>

					<description><![CDATA[<p>I’m thrilled to have our paper submission accepted to the . Cynthia Bennett and I will be busily preparing our paper for the always amazing event, this year in August/September in Boston. A care for beingmore (cap-)able Cynthia Bennett and Alex Taylor In this paper, we begin with Ingunn Moser’s and Maria Puig de la [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/4s-acceptance-2017/">Read More...<span class="screen-reader-text"> from Paper at 4S 2017</span></a></p>
<p>The post <a rel="nofollow" href="/4s-acceptance-2017/">Paper at 4S 2017</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>I’m thrilled to have our paper submission accepted to the <a id="tippy_tip4_5506_anchor"></a>. Cynthia Bennett and I will be busily preparing our paper for the always amazing event, this year in August/September in Boston.</p>
<div class="highlight" style="font-size:325%">A care for being<br>more (cap-)able</div>
<p><em>Cynthia Bennett and Alex Taylor</em></p>
<blockquote><p>In this paper, we begin with Ingunn Moser’s and Maria Puig de la Bellacasa’s generative notions of care and use them to expand how we understand capability. Drawing on fieldwork with blind and vision impaired people, we turn our attention to a materially enacted, unfolding ‘sense-ability’. This is a sensing that puts (cap)ability and care together, that understands ‘seeing-in-the-world’ as a practical affair that is, at once, knowing, effecting and affecting with others (humans or otherwise). Thus, we show not only that care can contest an ‘instrumentalism’ in forms of knowing and doing—by ‘re-affecting objectified worlds’ (Puig de la Bellacasa, 2011: 98)—but also give a greater clarity to how care can be, in practice, entangled in practice. This sense-ability seeks to be active, enlivening how we become capable; it is figured to be worked with, not finite and dictated by assumed bodily limits, but open to becoming-with and becoming-more. Borrowing from Vinciane Despret, this sense-ability is “to gain a body that does more things, that feels other events, and that is more and more able…” (2004: 120).</p></blockquote>
<blockquote style="font-size:smaller"><p>Despret, V. (2004). <a href="http://journals.sagepub.com/doi/abs/10.1177/1357034X04042938" target="_blank" rel="noopener noreferrer">The Body We Care For: Figures of Anthropo-zoo-genesis</a>. <em>Body &amp; Society</em>, 10(2–3), 111–134.<br>
Moser, I. (2011). <a href="http://journals.sagepub.com/doi/abs/10.1177/0162243910396349" target="_blank" rel="noopener noreferrer">Dementia and the Limits to Life</a>. ST&amp;HV, 36(5), 704–722.<br>
Puig de la Bellacasa, M. (2011). <a href="http://journals.sagepub.com/doi/abs/10.1177/0306312710380301" target="_blank" rel="noopener noreferrer">Matters of Care in Technoscience. Social Studies of Science</a>, 41(1), 85–106.</p></blockquote>
<div class="tippy" data-title="4S 2017 annual meeting" data-showheader="false" data-anchor="#tippy_tip4_5506_anchor">4S is the <a href="http://www.4sonline.org/" target="_blank" rel="noopener noreferrer">Society for the Social Studies of Science</a>. The annual meeting details are <a href="http://www.4sonline.org/meeting" target="_blank" rel="noopener noreferrer">here</a>.</div>
<p>The post <a rel="nofollow" href="/4s-acceptance-2017/">Paper at 4S 2017</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/4s-acceptance-2017/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>

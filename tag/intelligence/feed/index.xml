<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>intelligence - Alex Taylor</title>
	<atom:link href="http://ast.io/tag/intelligence/feed/" rel="self" type="application/rss+xml" />
	<link>http://ast.io/</link>
	<description>by Alex Taylor</description>
	<lastBuildDate>Mon, 05 Feb 2018 21:56:52 +0000</lastBuildDate>
	<language>en-GB</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.0</generator>
	<item>
		<title>CHI 2018 papers.</title>
		<link>http://ast.io/chi-2018-papers/</link>
					<comments>http://ast.io/chi-2018-papers/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Mon, 05 Feb 2018 21:56:52 +0000</pubDate>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Writing]]></category>
		<category><![CDATA[blind and vision impaired]]></category>
		<category><![CDATA[CHI]]></category>
		<category><![CDATA[HCI]]></category>
		<category><![CDATA[intelligence]]></category>
		<guid isPermaLink="false">http://ast.io/?p=3871</guid>

					<description><![CDATA[Anja Thieme, Cynthia L. Bennett, Cecily Morrison, Edward Cutrell and Alex Taylor (2018) “I can do everything but see!” – How People with Vision Impairments Negotiate their Abilities in Social Contexts. In Proceedings CHI ’18. ACM Press. [tippy title=“Abstract” showtitle=“false”]Abstract — This research takes an orientation to visual impairment (VI) that does not regard it [...]<p><a class="btn btn-secondary understrap-read-more-link" href="http://ast.io/chi-2018-papers/">Read More...<span class="screen-reader-text"> from CHI 2018 papers.</span></a></p>]]></description>
										<content:encoded><![CDATA[<div class="call-out">
<p>Anja Thieme, Cynthia L. Bennett, Cecily Morrison, Edward Cutrell and Alex Taylor (2018) <strong>“I can do everything but see!” – How People with Vision Impairments Negotiate their Abilities in Social Contexts.</strong> <em>In Proceedings CHI ’18</em>. ACM Press. [tippy title=“Abstract” showtitle=“false”]<strong>Abstract</strong> — This research takes an orientation to visual impairment (VI) that does not regard it as fixed or determined alone in or through the body. Instead, we consider (dis)ability as produced through interactions with the environment and configured by the people and technology within it. Specifically, we explore how abilities become negotiated through video ethnography with six VI athletes and spectators during the Rio 2016 Paralympics. We use generated in-depth examples to identify how technology can be a meaningful part of ability negotiations, emphasizing how these embed into the social interactions and lives of people with VI. In contrast to treating technology as a solution to a ‘sensory deficit’, we understand it to support the triangulation process of sense-making through provision of appropriate additional information. Further, we suggest that technology should not try and replace human assistance, but instead enable people with VI to better identify and interact with other people in-situ.[/tippy]</p>
<p><span class="entry-meta"><a href="http://ast.io/download/3859/" rel="noopener noreferrer" target="_blank">pdf</a> (875 downloads)</span></p>
<p style="margin-top:6rem">Ari Schlesinger, Kenton O’Hara and Alex Taylor (2018) <strong>Lets Talk about Race: Identity, Chatbots, and AI.</strong> <em>In Proceedings CHI ’18</em>. ACM Press. [tippy title=“Abstract” showtitle=“false”]<strong>Abstract</strong> — Why is it so hard for chatbots to talk about race? This work explores how the biased contents of databases, the syntactic focus of natural language processing, and the opaque nature of deep learning algorithms cause chatbots difficulty in handling race-talk. In each of these areas, the tensions between race and chatbots create new opportunities for people and machines. By making the abstract and disparate qualities of this problem space tangible, we can develop chatbots that are more capable of handling race-talk in its many forms. Our goal is to provide the HCI community with ways to begin addressing the question, how can chatbots handle race-talk in new and improved ways?[/tippy]</p>
<p><span class="entry-meta"><a href="http://ast.io/download/3850/" rel="noopener noreferrer" target="_blank">pdf</a> (1277 downloads)</span></p></div>
<div class="left-of-call-out">
<p>Very happy to have contributed to two papers being presented at the upcoming <a href="https://chi2018.acm.org/" rel="noopener noreferrer" target="_blank">CHI conference</a> this year. One reports on work with the blind and vision impaired a few of us have been involved in different ways (see <a href="http://ast.io/research/#capability" rel="noopener">here</a>). Broadly, we’ve used the piece to reflect on the relations between vision impairment and artificial intelligence, and set out directions for a possible design space.</p>
<p style="margin:3rem 0 2rem 0;">The second paper picks up on a new theme for me, but one closely related to past reflections and design work around <a href="http://ast.io/research/#intelauto">machine intelligence</a>. With the fantastic <a href="http://arischlesinger.com/" rel="noopener noreferrer" target="_blank">Ari Schlesinger</a> (GA Tech) leading the research, we examine the challenges faced in handling race talk (and racism) in human-bot interactions. Taking both Tai AI and the blacklist as starting points, we take seriously the computational underpinnings of chat bots and conversational agents, to underscore the role they have in sustaining troubling racial categories and the conditions they make possible for more just and equitable ways forward.</p>
</div>
]]></content:encoded>
					
					<wfw:commentRss>http://ast.io/chi-2018-papers/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Art and Tech Social at BOM</title>
		<link>http://ast.io/art-and-tech-social/</link>
					<comments>http://ast.io/art-and-tech-social/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Wed, 08 Nov 2017 12:46:46 +0000</pubDate>
				<category><![CDATA[Talks]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[intelligence]]></category>
		<guid isPermaLink="false">http://ast.io/?p=3679</guid>

					<description><![CDATA[Happy to have been at the BOM gallery in Birmingham yesterday, presenting with the great Kyle McDonald on intelligence and AI, with some YouTube animal videos thrown in. Hoorah! #artandtechsocial is back @BOMlab with @kcimc and @alxndrt pic.twitter.com/6wbvZFeBTl — Karen Newman (@karen_new_) November 7, 2017 [...]<p><a class="btn btn-secondary understrap-read-more-link" href="http://ast.io/art-and-tech-social/">Read More...<span class="screen-reader-text"> from Art and Tech Social at BOM</span></a></p>]]></description>
										<content:encoded><![CDATA[<p>Happy to have been at the <a href="http://www.bom.org.uk/" rel="noopener noreferrer" target="_blank">BOM</a> gallery in Birmingham yesterday, presenting with the great <a href="https://twitter.com/kcimc?ref_src=twsrc%5Etfw&amp;ref_url=https%3A%2F%2Ftwitter.com%2Fi%2Fnotifications" rel="noopener noreferrer" target="_blank">Kyle McDonald</a> on intelligence and AI, with some YouTube animal videos thrown in.</p>
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">Hoorah! <a href="https://twitter.com/hashtag/artandtechsocial?src=hash&amp;ref_src=twsrc%5Etfw">#artandtechsocial</a> is back <a href="https://twitter.com/BOMlab?ref_src=twsrc%5Etfw">@BOMlab</a> with <a href="https://twitter.com/kcimc?ref_src=twsrc%5Etfw">@kcimc</a> and <a href="https://twitter.com/alxndrt?ref_src=twsrc%5Etfw">@alxndrt</a> <a href="https://t.co/6wbvZFeBTl">pic.twitter.com/6wbvZFeBTl</a></p>
<p>— Karen Newman (@karen_new_) <a href="https://twitter.com/karen_new_/status/927968785398722560?ref_src=twsrc%5Etfw">November 7, 2017</a></p></blockquote>
<p> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
					<wfw:commentRss>http://ast.io/art-and-tech-social/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Interview with Nora Young on CBC Radio Spark Show</title>
		<link>http://ast.io/interview-cbc-radio-spark/</link>
					<comments>http://ast.io/interview-cbc-radio-spark/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Tue, 04 Oct 2016 12:20:38 +0000</pubDate>
				<category><![CDATA[Audio]]></category>
		<category><![CDATA[Press]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[birds]]></category>
		<category><![CDATA[intelligence]]></category>
		<guid isPermaLink="false">http://ast.io/?p=1620</guid>

					<description><![CDATA[I was interviewed just over a week ago by [tippy title=“CBC’s” showheader=“false”]Canadian public broadcaster[/tippy] Nora Young, for the great Spark programme, aired on CBC Radio One. In short, I try to give Nora a sense of how AI could open up some radically different possibilities if we were able to approach intelligence differently. I try [...]<p><a class="btn btn-secondary understrap-read-more-link" href="http://ast.io/interview-cbc-radio-spark/">Read More...<span class="screen-reader-text"> from Interview with Nora Young on CBC Radio Spark Show</span></a></p>]]></description>
										<content:encoded><![CDATA[<p>I was interviewed just over a week ago by [tippy title=“CBC’s” showheader=“false”]<a href="http://www.cbc.ca/" target="_blank" rel="noopener noreferrer">Canadian public broadcaster</a>[/tippy] <a href="https://en.wikipedia.org/wiki/Nora_Young" target="_blank" rel="noopener noreferrer">Nora Young</a>, for the great <a href="http://www.cbc.ca/radio/spark/about" target="_blank" rel="noopener noreferrer">Spark</a> programme, aired on CBC Radio One.<br>
In short, I try to give Nora a sense of how AI could open up some radically different possibilities if we were able to approach intelligence differently. I try to capture how we might see intelligence not in restrictive human terms (as stable cognitive capacities in the head/mind), but as something always emergent, always enacted and tied to the many unfolding relations we find ourselves entangled in. I see this to be a generative orientation to AI, building on ideas from Donna Haraway, Isabelle Stengers, Vinciane Despret, Sarah Whatmore and many others grappling with the possibilities of us extending our capabilities, of being somehow more-than-human.<br>
If you’re in Canada, the programme is broadcast this coming Sunday afternoon at 1:05 PM local time (in most parts of Canada) and again on Wednesday at 2:05 PM. Alternatively, my segment of the show is available <a href="http://www.cbc.ca/radio/spark/329-a-new-standard-for-intelligence-online-bartering-and-more-1.3782044/how-should-we-define-intelligence-1.3782055" target="_blank" rel="noopener noreferrer">here</a>, titled:</p>
<div class="highlight" style="font-size:2.2rem;">
<a href="http://www.cbc.ca/radio/spark/329-a-new-standard-for-intelligence-online-bartering-and-more-1.3782044/how-should-we-define-intelligence-1.3782055" target="_blank" rel="noopener noreferrer">How should we<br>define “intelligence”?</a>
</div>
<p>I want to give a special thanks to <a href="http://marcuscarter.com/" target="_blank" rel="noopener noreferrer">Marcus Carter</a> and the <a href="http://www.socialnui.unimelb.edu.au/" target="_blank" rel="noopener noreferrer">University of Melbourne’s Social NUI Centre</a> for allowing me to share their amazing <a href="http://www.socialnui.unimelb.edu.au/research/zoos/" target="_blank" rel="noopener noreferrer">work with Orangutans</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>http://ast.io/interview-cbc-radio-spark/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Artificial Intelligence: asking the right questions</title>
		<link>http://ast.io/ai-asking-the-right-questions/</link>
					<comments>http://ast.io/ai-asking-the-right-questions/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Wed, 17 Aug 2016 15:08:57 +0000</pubDate>
				<category><![CDATA[Presenting]]></category>
		<category><![CDATA[Writing]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[intelligence]]></category>
		<guid isPermaLink="false">http://ast.io/?p=1522</guid>

					<description><![CDATA[Nesta&#160;kindly&#160;invited me to one of their ‘hot topics’&#160;events a couple of weeks ago to present a provocation on AI and human-computer interaction. They also asked for me to write a few words that they’ve now published on the “TheLong+Short” blog here.&#160;I append the original text to my provocation below. I came across this photo on [...]<p><a class="btn btn-secondary understrap-read-more-link" href="http://ast.io/ai-asking-the-right-questions/">Read More...<span class="screen-reader-text"> from Artificial Intelligence: asking the right questions</span></a></p>]]></description>
										<content:encoded><![CDATA[<p><a href="http://www.nesta.org.uk/" target="_blank" rel="noopener noreferrer">Nesta</a>&nbsp;kindly&nbsp;invited me to one of their ‘<a href="http://www.nesta.org.uk/event/human-meet-computer" target="_blank" rel="noopener noreferrer">hot topics</a>’&nbsp;events a couple of weeks ago to present a provocation on AI and human-computer interaction. They also asked for me to write a few words that they’ve now published on the “TheLong+Short” blog <a href="http://thelongandshort.org/machines/beyond-human-intelligence" target="_blank" rel="noopener noreferrer">here</a>.&nbsp;I append the original text to my provocation below.<br>
I came across this photo on my computer today (sorry, I’ve looked to see if I can attribute it to someone, but so far failed). It’s a lovely image&nbsp;in it’s own right, playing with a vintage quality to the future, but in this context I think it does invite the question&nbsp;‘is this the limit of our imaginations?’ I’d like to suggest AI might open us up to so much more.<span id="more-1522"></span><br>
<img loading="lazy" class="wp-image-1566" style="border-radius: 10px" src="http://ast.io/wp-content/uploads/2016/08/children-with-robot-194x300.jpg" alt="Children with robot" width="240" height="371"><br>
&nbsp;</p>
<div class="highlight-float">Asking the<br>Right Questions[foot]I humbly borrow this phrasing from <a href="http://www.vincianedespret.be/" target="_blank" rel="noopener noreferrer">Vinciane Despret</a> who has invested a career in figuring out the right questions to ask of animals and most recently published the fabulous book “<a href="https://www.upress.umn.edu/book-division/books/what-would-animals-say-if-we-asked-the-right" target="_blank" rel="noopener noreferrer">What would animals say if we asked the right questions?”</a>[/foot]</div>
<blockquote><p>It seems to me that again and again, in our visions of human computer interaction, we keep coming back to a peculiar notion of human intelligence as a benchmark for what we want our machines to behave like — chess players, go players, conversational agents, car drivers, humanoid robots, etc.<br>
To me, this seems to be a terribly restrictive idea of intelligence, one that limits our imaginations and constrains what the innovations in machine learning and AI could offer. To be blunt: our clunky ideas of human intelligence, smartness, emotion, and so on, are things we’re so deeply invested in, intellectually and culturally, that they distract us from far more promising possibilities.<br>
To get us thinking differently, I want to experiment a little with some questions about what we think intelligence is, and what kind of intelligence we might want in the machines we’re building and that we’ll eventually come to live with. Through a different way of viewing the challenges, I want to ask what other kinds of intelligence we might just imagine in our interactions with machines?<br>
To help develop this line of questioning, let me begin with a parable of sorts, one that might seem to diverge from the topic at hand, but I hope to show has an apposite lesson:<br>
For decades, animal behaviourists have invested their research energies in assessing whether birds can talk and whether, with that talk, they exhibit higher-functioning cognitive abilities, that is ones closer to our own. In the laboratory — through all sorts of experimental configurations — mynah birds, parrots, macaws etc. have been pushed and prodded to talk. What’s hardly surprising is that the results point towards conclusive evidence that birds have a less sophisticated cognitive capacity to let us say other highly evolved nonhumans such as primates, and of course ourselves. In experimental conditions, birds perform badly (as a matter of fact they do their utmost to sabotage the equipment.[foot]This is taken from Despret’s book. She cites the following as the source: Griffin, D. (1992). Animal Minds. Chicago: Chicago University Press.[/foot] To put it another way, it turns out that mynahs, macaws, parrots, and the like just don’t like to talk under the experimental conditions they are subject to.<br>
However, outside the laboratory, at least in a limited number of cases, it seems that if people invest in developing a relationship with these birds, one in which the needs and desires are understood to be things that are negotiated and developed over time — what the philosopher and ethnologist Vinciane Depret refers to as “a constant movement of attunement” [foot]Vinciane Despret 2008. The Becomings of Subjectivity in Animal Worlds. <em>Subjectivity</em>, 23 (1), p 125.[/foot] — they can start to talk and they can at the end of a day (literally) end up saying things like:</p>
<div class="highlight">You be good, see you tomorrow.<br>I love you.[foot]Irene Pepperberg reports that her parrot Alex used to say this to her every evening. It has been widely reported not least in the <a href="http://www.telegraph.co.uk/culture/books/authorinterviews/10523254/Irene-Pepperberg-on-teaching-Alex-the-parrot-to-count.html" target="_blank" rel="noopener noreferrer">Telegraph</a>. I first came across the story via Despret in both her book and her 2008 paper in <a href="http://link.springer.com/article/10.1057%2Fsub.2008.15" target="_blank" rel="noopener noreferrer"><em>Subjectivity</em></a>.[/foot]</div>
<p>Now, my point here isn’t yet another argument for or against anthropomorphising birds, animals or even machines. My interest — again, taking from Despret — is in how we might start to ask a different set of questions: In the case of birds, it’s not whether we can generalise to say that birds are intrinsically like/unlike humans or, more specifically, whether they can talk like humans. Rather, can we ask what are the conditions through which we can begin to talk with them, and that they might talk back?<br>
To bring this back to our topic, can we ask what the conditions would be for something akin to intelligence to surface in our human-machine interactions? What questions do we need to ask of those things we interact with to allow an intelligence to surface? It’s this turn to a‑thinking-about-the-conditions that are created and what-might-just-be-possible that invites us to ask some very different questions, questions not about some intrinsic quality of animal or machine intelligence, but of humans and nonhumans altogether, of a wider set of relations and entanglements that bring intelligence into being.<br>
So what might these different conditions be? And how might we imagine something else through the entanglements between humans and machines? With questions like these I think we open ourselves up to a vast array of possibilities, but let me offer just one idea to illustrate. I want to suggest that through the infrastructural capacities of vastly distributed systems and the production of data, we could begin to see the conditions for difference.<br>
Take the example of the [tippy title=“widely reported glitch” showheader=“false”]See the original story from <a href="http://fusion.net/author/kashmir-hill/" target="_blank" rel="noopener noreferrer">Kashmir Hill</a> <a href="http://fusion.net/story/287592/internet-mapping-glitch-kansas-farm/" target="_blank" rel="noopener noreferrer">here</a> and a recent followup Guardian piece <a href="https://www.theguardian.com/technology/2016/aug/09/maxmind-mapping-lawsuit-kansas-farm-ip-address" target="_blank" rel="noopener noreferrer">here</a>.[/tippy] in IP geolocation from Maxmind, the US-based provider of “IP intelligence”. Through a system designed to locate people using their connected devices, we see how certain demographic categories are sustained and cemented: what do people living here buy? Or where do nefarious interact activities originate? And, in some cases, we see how the technical particularities of such an algorithmic system can give rise to a so-called glitch where, because of their geographic location, people and households are inadvertently accused of criminal activity. If there’s any intelligence here, it’s invested in counting and bucketing people into coarse and problematic socio-economic categories.<br>
My question would be to ask how this configuration of geography, people and technology might be changed to surface something else. How might the conditions be altered so that populations are seen not in overly simplistic and at times error-prone ways, but in ways that open us up to different possibilities. How might they be used, for instance, to understand how people could be counted differently, how new classifications might be surfaced that open us up to the other ways we inhabit and build relations to spaces. And what if the specific algorithmic limitations of the system weren’t bracketed off, and treated as noise, but used to ask who is not being counted here, and how might they be?<br>
I wouldn’t want to pretend to have any concrete or half-baked answers here, but I think we need to take seriously the invitation to ask different questions like these. They will be what surface an intelligence that is more than mimicry and invested, instead, in how we hope to live our lives. Thus, we might ask: What is it each of us might learn from using a system that responds, intelligently, to the relations between ourselves and place? What, derived from a panoply of data sources and billions of human-machine interactions, might each of us develop a sense of? How might each of us truly accomplish something, together, with an emerging back and forth of engagements and interactions?<br>
In interacting with an intelligence of this sort, we may not need to know its inner workings, just as we don’t need to know the inner workings of someone else (or for that matter of another species) to talk to them. What we do need are the conditions to actively produce something in common, to bit by bit “result in shared perspectives, intelligences and intentions, resemblances, inversions and exchanges of properties.” [foot]Vinciane Despret 2008. The Becomings of Subjectivity in Animal Worlds. <em>Subjectivity</em>, 23 (1), p 135.[/foot]</p>
</blockquote>]]></content:encoded>
					
					<wfw:commentRss>http://ast.io/ai-asking-the-right-questions/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>

<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>AI Archives | Alex Taylor</title>
	<atom:link href="/tag/ai/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>by Alex Taylor</description>
	<lastBuildDate>Fri, 17 Dec 2021 15:38:15 +0000</lastBuildDate>
	<language>en-GB</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.0</generator>
	<item>
		<title>Panel talk: Prototyping AI ethics futures—Rights, access and refusal</title>
		<link>/panel-talk-prototyping-ai-ethics-futures-rights-access-and-refusal/</link>
					<comments>/panel-talk-prototyping-ai-ethics-futures-rights-access-and-refusal/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Sun, 20 Jun 2021 11:47:51 +0000</pubDate>
				<category><![CDATA[Events]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[Talks]]></category>
		<category><![CDATA[access]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[dis/ability]]></category>
		<guid isPermaLink="false">/?p=5848</guid>

					<description><![CDATA[<p>Panel talk at 1:00pm–2:30pm, 23 June 2021 (BST), in association with Ada Lovelace Institute, The British Academy and The Arts and Humanities Research council. Join us this Wednesday 23th at 1pm BST for the@justainet panel on “Rights, Access and Refusal” with @crystaljjlee @alxndrt and @maramills. Response from @sarahchander and chaired by @anthroptimist and @_louhicky https://t.co/3UUdNNzOsf [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/panel-talk-prototyping-ai-ethics-futures-rights-access-and-refusal/">Read More...<span class="screen-reader-text"> from Panel talk: Prototyping AI ethics futures—Rights, access and refusal</span></a></p>
<p>The post <a rel="nofollow" href="/panel-talk-prototyping-ai-ethics-futures-rights-access-and-refusal/">Panel talk: Prototyping AI ethics futures—Rights, access and refusal</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>Panel talk at 1:00pm–2:30pm, 23 June 2021 (BST), in association with <a href="https://www.adalovelaceinstitute.org/event/prototyping-ai-ethics-futures-rights-access-refusal/" rel="noopener" target="_blank">Ada Lovelace Institute</a>, <a href="https://www.thebritishacademy.ac.uk/" rel="noopener" target="_blank">The British Academy</a> and <a href="https://ahrc.ukri.org/" rel="noopener" target="_blank">The Arts and Humanities Research council</a>.</p>
<div class="row">
<div class="col-sm-9 col-md-8 mt-3">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Join us this Wednesday 23th at 1pm BST for the<a href="https://twitter.com/justainet?ref_src=twsrc%5Etfw">@justainet</a> panel on “Rights, Access and Refusal” with <a href="https://twitter.com/crystaljjlee?ref_src=twsrc%5Etfw">@crystaljjlee</a> <a href="https://twitter.com/alxndrt?ref_src=twsrc%5Etfw">@alxndrt</a> and <a href="https://twitter.com/maramills?ref_src=twsrc%5Etfw">@maramills</a>. Response from <a href="https://twitter.com/sarahchander?ref_src=twsrc%5Etfw">@sarahchander</a> and chaired by <a href="https://twitter.com/anthroptimist?ref_src=twsrc%5Etfw">@anthroptimist</a> and <a href="https://twitter.com/_louhicky?ref_src=twsrc%5Etfw">@_louhicky</a> <a href="https://t.co/3UUdNNzOsf">https://t.co/3UUdNNzOsf</a></p>
<p>— JUST AI Network (@justainet) <a href="https://twitter.com/justainet/status/1406239804824641536?ref_src=twsrc%5Etfw">June 19, 2021</a></p></blockquote>
<p> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8">
</div>
</div>
<p></script></p>
</div></div><p>The post <a rel="nofollow" href="/panel-talk-prototyping-ai-ethics-futures-rights-access-and-refusal/">Panel talk: Prototyping AI ethics futures—Rights, access and refusal</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/panel-talk-prototyping-ai-ethics-futures-rights-access-and-refusal/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Art and Tech Social at BOM</title>
		<link>/art-and-tech-social/</link>
					<comments>/art-and-tech-social/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Wed, 08 Nov 2017 12:46:46 +0000</pubDate>
				<category><![CDATA[Talks]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[intelligence]]></category>
		<guid isPermaLink="false">/?p=3679</guid>

					<description><![CDATA[<p>Happy to have been at the BOM gallery in Birmingham yesterday, presenting with the great Kyle McDonald on intelligence and AI, with some YouTube animal videos thrown in. Hoorah! #artandtechsocial is back @BOMlab with @kcimc and @alxndrt pic.twitter.com/6wbvZFeBTl — Karen Newman (@karen_new_) November 7, 2017 [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/art-and-tech-social/">Read More...<span class="screen-reader-text"> from Art and Tech Social at BOM</span></a></p>
<p>The post <a rel="nofollow" href="/art-and-tech-social/">Art and Tech Social at BOM</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>Happy to have been at the <a href="http://www.bom.org.uk/" rel="noopener noreferrer" target="_blank">BOM</a> gallery in Birmingham yesterday, presenting with the great <a href="https://twitter.com/kcimc?ref_src=twsrc%5Etfw&amp;ref_url=https%3A%2F%2Ftwitter.com%2Fi%2Fnotifications" rel="noopener noreferrer" target="_blank">Kyle McDonald</a> on intelligence and AI, with some YouTube animal videos thrown in.</p>
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">Hoorah! <a href="https://twitter.com/hashtag/artandtechsocial?src=hash&amp;ref_src=twsrc%5Etfw">#artandtechsocial</a> is back <a href="https://twitter.com/BOMlab?ref_src=twsrc%5Etfw">@BOMlab</a> with <a href="https://twitter.com/kcimc?ref_src=twsrc%5Etfw">@kcimc</a> and <a href="https://twitter.com/alxndrt?ref_src=twsrc%5Etfw">@alxndrt</a> <a href="https://t.co/6wbvZFeBTl">pic.twitter.com/6wbvZFeBTl</a></p>
<p>— Karen Newman (@karen_new_) <a href="https://twitter.com/karen_new_/status/927968785398722560?ref_src=twsrc%5Etfw">November 7, 2017</a></p></blockquote>
<p> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>The post <a rel="nofollow" href="/art-and-tech-social/">Art and Tech Social at BOM</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/art-and-tech-social/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Interview with Nora Young on CBC Radio Spark Show</title>
		<link>/interview-cbc-radio-spark/</link>
					<comments>/interview-cbc-radio-spark/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Tue, 04 Oct 2016 12:20:38 +0000</pubDate>
				<category><![CDATA[Audio]]></category>
		<category><![CDATA[Press]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[birds]]></category>
		<category><![CDATA[intelligence]]></category>
		<guid isPermaLink="false">/?p=1620</guid>

					<description><![CDATA[<p>I was interviewed just over a week ago by Nora Young, for the great Spark programme, aired on CBC Radio One. In short, I try to give Nora a sense of how AI could open up some radically different possibilities if we were able to approach intelligence differently. I try to capture how we might [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/interview-cbc-radio-spark/">Read More...<span class="screen-reader-text"> from Interview with Nora Young on CBC Radio Spark Show</span></a></p>
<p>The post <a rel="nofollow" href="/interview-cbc-radio-spark/">Interview with Nora Young on CBC Radio Spark Show</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>I was interviewed just over a week ago by <a id="tippy_tip0_498_anchor"></a> <a href="https://en.wikipedia.org/wiki/Nora_Young" target="_blank" rel="noopener noreferrer">Nora Young</a>, for the great <a href="http://www.cbc.ca/radio/spark/about" target="_blank" rel="noopener noreferrer">Spark</a> programme, aired on CBC Radio One.<br>
In short, I try to give Nora a sense of how AI could open up some radically different possibilities if we were able to approach intelligence differently. I try to capture how we might see intelligence not in restrictive human terms (as stable cognitive capacities in the head/mind), but as something always emergent, always enacted and tied to the many unfolding relations we find ourselves entangled in. I see this to be a generative orientation to AI, building on ideas from Donna Haraway, Isabelle Stengers, Vinciane Despret, Sarah Whatmore and many others grappling with the possibilities of us extending our capabilities, of being somehow more-than-human.<br>
If you’re in Canada, the programme is broadcast this coming Sunday afternoon at 1:05 PM local time (in most parts of Canada) and again on Wednesday at 2:05 PM. Alternatively, my segment of the show is available <a href="http://www.cbc.ca/radio/spark/329-a-new-standard-for-intelligence-online-bartering-and-more-1.3782044/how-should-we-define-intelligence-1.3782055" target="_blank" rel="noopener noreferrer">here</a>, titled:</p>
<div class="highlight" style="font-size:2.2rem;">
<a href="http://www.cbc.ca/radio/spark/329-a-new-standard-for-intelligence-online-bartering-and-more-1.3782044/how-should-we-define-intelligence-1.3782055" target="_blank" rel="noopener noreferrer">How should we<br>define “intelligence”?</a>
</div>
<p>I want to give a special thanks to <a href="http://marcuscarter.com/" target="_blank" rel="noopener noreferrer">Marcus Carter</a> and the <a href="http://www.socialnui.unimelb.edu.au/" target="_blank" rel="noopener noreferrer">University of Melbourne’s Social NUI Centre</a> for allowing me to share their amazing <a href="http://www.socialnui.unimelb.edu.au/research/zoos/" target="_blank" rel="noopener noreferrer">work with Orangutans</a>.</p>
<div class="tippy" data-title="CBC's" data-showheader="false" data-anchor="#tippy_tip0_498_anchor"><a href="http://www.cbc.ca/" target="_blank" rel="noopener noreferrer">Canadian public broadcaster</a></div>
<p>The post <a rel="nofollow" href="/interview-cbc-radio-spark/">Interview with Nora Young on CBC Radio Spark Show</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/interview-cbc-radio-spark/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Artificial Intelligence: asking the right questions</title>
		<link>/ai-asking-the-right-questions/</link>
					<comments>/ai-asking-the-right-questions/#respond</comments>
		
		<dc:creator><![CDATA[Alex Taylor]]></dc:creator>
		<pubDate>Wed, 17 Aug 2016 15:08:57 +0000</pubDate>
				<category><![CDATA[Presenting]]></category>
		<category><![CDATA[Writing]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[intelligence]]></category>
		<guid isPermaLink="false">/?p=1522</guid>

					<description><![CDATA[<p>Nesta&#160;kindly&#160;invited me to one of their ‘hot topics’&#160;events a couple of weeks ago to present a provocation on AI and human-computer interaction. They also asked for me to write a few words that they’ve now published on the “TheLong+Short” blog here.&#160;I append the original text to my provocation below. I came across this photo on [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="/ai-asking-the-right-questions/">Read More...<span class="screen-reader-text"> from Artificial Intelligence: asking the right questions</span></a></p>
<p>The post <a rel="nofollow" href="/ai-asking-the-right-questions/">Artificial Intelligence: asking the right questions</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><a href="http://www.nesta.org.uk/" target="_blank" rel="noopener noreferrer">Nesta</a>&nbsp;kindly&nbsp;invited me to one of their ‘<a href="http://www.nesta.org.uk/event/human-meet-computer" target="_blank" rel="noopener noreferrer">hot topics</a>’&nbsp;events a couple of weeks ago to present a provocation on AI and human-computer interaction. They also asked for me to write a few words that they’ve now published on the “TheLong+Short” blog <a href="http://thelongandshort.org/machines/beyond-human-intelligence" target="_blank" rel="noopener noreferrer">here</a>.&nbsp;I append the original text to my provocation below.<br>
I came across this photo on my computer today (sorry, I’ve looked to see if I can attribute it to someone, but so far failed). It’s a lovely image&nbsp;in it’s own right, playing with a vintage quality to the future, but in this context I think it does invite the question&nbsp;‘is this the limit of our imaginations?’ I’d like to suggest AI might open us up to so much more.<span id="more-1522"></span><br>
<img loading="lazy" class="wp-image-1566" style="border-radius: 10px" src="/wp-content/uploads/2016/08/children-with-robot-194x300.jpg" alt="Children with robot" width="240" height="371"><br>
&nbsp;</p>
<div class="highlight-float">Asking the<br>Right Questions<a id="tippy_tip1_3356_anchor"></a></div>
<blockquote><p>It seems to me that again and again, in our visions of human computer interaction, we keep coming back to a peculiar notion of human intelligence as a benchmark for what we want our machines to behave like — chess players, go players, conversational agents, car drivers, humanoid robots, etc.<br>
To me, this seems to be a terribly restrictive idea of intelligence, one that limits our imaginations and constrains what the innovations in machine learning and AI could offer. To be blunt: our clunky ideas of human intelligence, smartness, emotion, and so on, are things we’re so deeply invested in, intellectually and culturally, that they distract us from far more promising possibilities.<br>
To get us thinking differently, I want to experiment a little with some questions about what we think intelligence is, and what kind of intelligence we might want in the machines we’re building and that we’ll eventually come to live with. Through a different way of viewing the challenges, I want to ask what other kinds of intelligence we might just imagine in our interactions with machines?<br>
To help develop this line of questioning, let me begin with a parable of sorts, one that might seem to diverge from the topic at hand, but I hope to show has an apposite lesson:<br>
For decades, animal behaviourists have invested their research energies in assessing whether birds can talk and whether, with that talk, they exhibit higher-functioning cognitive abilities, that is ones closer to our own. In the laboratory — through all sorts of experimental configurations — mynah birds, parrots, macaws etc. have been pushed and prodded to talk. What’s hardly surprising is that the results point towards conclusive evidence that birds have a less sophisticated cognitive capacity to let us say other highly evolved nonhumans such as primates, and of course ourselves. In experimental conditions, birds perform badly (as a matter of fact they do their utmost to sabotage the equipment.<a id="tippy_tip2_4999_anchor"></a> To put it another way, it turns out that mynahs, macaws, parrots, and the like just don’t like to talk under the experimental conditions they are subject to.<br>
However, outside the laboratory, at least in a limited number of cases, it seems that if people invest in developing a relationship with these birds, one in which the needs and desires are understood to be things that are negotiated and developed over time — what the philosopher and ethnologist Vinciane Depret refers to as “a constant movement of attunement” <a id="tippy_tip3_9990_anchor"></a> — they can start to talk and they can at the end of a day (literally) end up saying things like:</p>
<div class="highlight">You be good, see you tomorrow.<br>I love you.<a id="tippy_tip4_2078_anchor"></a></div>
<p>Now, my point here isn’t yet another argument for or against anthropomorphising birds, animals or even machines. My interest — again, taking from Despret — is in how we might start to ask a different set of questions: In the case of birds, it’s not whether we can generalise to say that birds are intrinsically like/unlike humans or, more specifically, whether they can talk like humans. Rather, can we ask what are the conditions through which we can begin to talk with them, and that they might talk back?<br>
To bring this back to our topic, can we ask what the conditions would be for something akin to intelligence to surface in our human-machine interactions? What questions do we need to ask of those things we interact with to allow an intelligence to surface? It’s this turn to a‑thinking-about-the-conditions that are created and what-might-just-be-possible that invites us to ask some very different questions, questions not about some intrinsic quality of animal or machine intelligence, but of humans and nonhumans altogether, of a wider set of relations and entanglements that bring intelligence into being.<br>
So what might these different conditions be? And how might we imagine something else through the entanglements between humans and machines? With questions like these I think we open ourselves up to a vast array of possibilities, but let me offer just one idea to illustrate. I want to suggest that through the infrastructural capacities of vastly distributed systems and the production of data, we could begin to see the conditions for difference.<br>
Take the example of the <a id="tippy_tip5_914_anchor"></a> in IP geolocation from Maxmind, the US-based provider of “IP intelligence”. Through a system designed to locate people using their connected devices, we see how certain demographic categories are sustained and cemented: what do people living here buy? Or where do nefarious interact activities originate? And, in some cases, we see how the technical particularities of such an algorithmic system can give rise to a so-called glitch where, because of their geographic location, people and households are inadvertently accused of criminal activity. If there’s any intelligence here, it’s invested in counting and bucketing people into coarse and problematic socio-economic categories.<br>
My question would be to ask how this configuration of geography, people and technology might be changed to surface something else. How might the conditions be altered so that populations are seen not in overly simplistic and at times error-prone ways, but in ways that open us up to different possibilities. How might they be used, for instance, to understand how people could be counted differently, how new classifications might be surfaced that open us up to the other ways we inhabit and build relations to spaces. And what if the specific algorithmic limitations of the system weren’t bracketed off, and treated as noise, but used to ask who is not being counted here, and how might they be?<br>
I wouldn’t want to pretend to have any concrete or half-baked answers here, but I think we need to take seriously the invitation to ask different questions like these. They will be what surface an intelligence that is more than mimicry and invested, instead, in how we hope to live our lives. Thus, we might ask: What is it each of us might learn from using a system that responds, intelligently, to the relations between ourselves and place? What, derived from a panoply of data sources and billions of human-machine interactions, might each of us develop a sense of? How might each of us truly accomplish something, together, with an emerging back and forth of engagements and interactions?<br>
In interacting with an intelligence of this sort, we may not need to know its inner workings, just as we don’t need to know the inner workings of someone else (or for that matter of another species) to talk to them. What we do need are the conditions to actively produce something in common, to bit by bit “result in shared perspectives, intelligences and intentions, resemblances, inversions and exchanges of properties.” <a id="tippy_tip6_4647_anchor"></a></p>
<div class="tippy" data-title="1" data-href="/ai-asking-the-right-questions/#foot_text_1522_1" data-class="annie_footnoteRef annie_custom" data-name="foot_loc_1522_1" data-showheader data-anchor="#tippy_tip1_3356_anchor">I humbly borrow this phrasing from <a href="http://www.vincianedespret.be/" target="_blank" rel="noopener noreferrer">Vinciane Despret</a> who has invested a career in figuring out the right questions to ask of animals and most recently published the fabulous book “<a href="https://www.upress.umn.edu/book-division/books/what-would-animals-say-if-we-asked-the-right" target="_blank" rel="noopener noreferrer">What would animals say if we asked the right questions?”</a></div>
<div class="tippy" data-title="2" data-href="/ai-asking-the-right-questions/#foot_text_1522_2" data-class="annie_footnoteRef annie_custom" data-name="foot_loc_1522_2" data-showheader data-anchor="#tippy_tip2_4999_anchor">This is taken from Despret’s book. She cites the following as the source: Griffin, D. (1992). Animal Minds. Chicago: Chicago University Press.</div>
<div class="tippy" data-title="3" data-href="/ai-asking-the-right-questions/#foot_text_1522_3" data-class="annie_footnoteRef annie_custom" data-name="foot_loc_1522_3" data-showheader data-anchor="#tippy_tip3_9990_anchor">Vinciane Despret 2008. The Becomings of Subjectivity in Animal Worlds. <em>Subjectivity</em>, 23 (1), p 125.</div>
<div class="tippy" data-title="4" data-href="/ai-asking-the-right-questions/#foot_text_1522_4" data-class="annie_footnoteRef annie_custom" data-name="foot_loc_1522_4" data-showheader data-anchor="#tippy_tip4_2078_anchor">Irene Pepperberg reports that her parrot Alex used to say this to her every evening. It has been widely reported not least in the <a href="http://www.telegraph.co.uk/culture/books/authorinterviews/10523254/Irene-Pepperberg-on-teaching-Alex-the-parrot-to-count.html" target="_blank" rel="noopener noreferrer">Telegraph</a>. I first came across the story via Despret in both her book and her 2008 paper in <a href="http://link.springer.com/article/10.1057%2Fsub.2008.15" target="_blank" rel="noopener noreferrer"><em>Subjectivity</em></a>.</div>
<div class="tippy" data-title="widely reported glitch" data-showheader="false" data-anchor="#tippy_tip5_914_anchor">See the original story from <a href="http://fusion.net/author/kashmir-hill/" target="_blank" rel="noopener noreferrer">Kashmir Hill</a> <a href="http://fusion.net/story/287592/internet-mapping-glitch-kansas-farm/" target="_blank" rel="noopener noreferrer">here</a> and a recent followup Guardian piece <a href="https://www.theguardian.com/technology/2016/aug/09/maxmind-mapping-lawsuit-kansas-farm-ip-address" target="_blank" rel="noopener noreferrer">here</a>.</div>
<div class="tippy" data-title="5" data-href="/ai-asking-the-right-questions/#foot_text_1522_5" data-class="annie_footnoteRef annie_custom" data-name="foot_loc_1522_5" data-showheader data-anchor="#tippy_tip6_4647_anchor">Vinciane Despret 2008. The Becomings of Subjectivity in Animal Worlds. <em>Subjectivity</em>, 23 (1), p 135.</div>
</blockquote><p>The post <a rel="nofollow" href="/ai-asking-the-right-questions/">Artificial Intelligence: asking the right questions</a> appeared first on <a rel="nofollow" href="/">Alex Taylor</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/ai-asking-the-right-questions/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
